from transformers import pipeline
import streamlit as st
import os
from streamlit_mic_recorder import mic_recorder

# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
task_type = 'automatic-speech-recognition'            # –ó–∞–¥–∞–µ–º —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞
model_path = "path/to/whisper-small-ru"    # –ó–∞–¥–∞–µ–º –ø—É—Ç—å –¥–æ –º–æ–¥–µ–ª–∏
token_path = "path/to/whisper-small-ru"    # –ó–∞–¥–∞–µ–º –ø—É—Ç—å –¥–æ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞


# –§—É–Ω–∫—Ü–∏–∏
def model_result(file_path, task_type, model_path, token_path):
    pipe = pipeline(task=task_type, model=model_path,
                    tokenizer=token_path, device=0)

    text = pipe(file_path)["text"]
    return text

def result(file_path, task_type, model_path, token_path, output_audio_file_name, transcript_path):
    with st.spinner(f"–°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏... üí´"):
        trans = model_result(file_path, task_type, model_path, token_path)

        output_txt_file = str(output_audio_file_name.split('.')[0]+".txt")

        with open(os.path.join(transcript_path, output_txt_file), "w", encoding='utf8') as f:
            f.write(trans)
        output_file = open(os.path.join(transcript_path,output_txt_file), "r", encoding='utf8')
        output_file_data = output_file.read()

    st.write("–†–µ–∑—É–ª—å—Ç–∞—Ç: ")
    st.write(trans)
    st.write('\n')
    st.write('\n')
    st.write('–í—ã –º–æ–∂–µ—Ç–µ —Å–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏ —Å–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∑–∞–Ω–æ–≤–æ')

    if st.download_button(
                            label="–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç üìù",
                            data=output_file_data,
                            file_name=output_txt_file,
                            mime='text/plain'
                        ):
        st.balloons()
        st.success('‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ !!')   

# –ö–æ–¥ —Ä–∞–±–æ—Ç—ã –ø—Ä–æ–≥—Ä–∞–º–º—ã
st.set_page_config(
    page_title="Whisper based ASR",
    page_icon="musical_note",
    layout="wide",
    initial_sidebar_state="auto",
)

upload_path = "./whisp_st/uploads/"
download_path = "./whisp_st/downloads/"
transcript_path = "./whisp_st/transcripts/"

st.title("üó£ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ–≤–æ–¥ —Ä—É—Å—Å–∫–æ–π —Ä–µ—á–∏ –≤ —Ç–µ–∫—Å—Ç –Ω–∞ small –º–æ–¥–µ–ª–∏ Whisper‚ú®")
st.text("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω")
choose = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö", ['–ó–∞–ø–∏—Å—å –∏–∑ —Ñ–∞–π–ª–∞', '–ó–∞–ø–∏—Å—å —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞'])
if "–ó–∞–ø–∏—Å—å –∏–∑ —Ñ–∞–π–ª–∞" in choose:
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª", type=["wav","mp3","ogg","wma","aac","flac","mp4","flv"])

    if uploaded_file:
        file_path = os.path.join(upload_path,uploaded_file.name)
        with open(file_path,"wb") as f:
            f.write((uploaded_file).getbuffer())
        with st.spinner(f"–ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ ... üí´"):
            output_audio_file_name = uploaded_file.name

        if st.button("–°–æ–∑–¥–∞—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é"):
            result(file_path, task_type, model_path, token_path, output_audio_file_name, transcript_path)

elif '–ó–∞–ø–∏—Å—å —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞' in choose:
    streamfile = mic_recorder(start_prompt="–ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å ‚è∫Ô∏è",stop_prompt="–ó–∞–∫–æ–Ω—á–∏—Ç—å –∑–∞–ø–∏—Å—å ‚èπÔ∏è",key='recorder')

    if streamfile:
        file_path = os.path.join(upload_path,'Record.wav')
        with open(file_path,"wb") as f:
            f.write(streamfile['bytes'])
        with st.spinner(f"–ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ ... üí´"):
            output_audio_file_name = 'Record.wav'
        
        if st.button("–°–æ–∑–¥–∞—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é"):
            result(file_path, task_type, model_path, token_path, output_audio_file_name, transcript_path)